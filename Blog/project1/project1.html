<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css"
    integrity="sha512-1ycn6IcaQQ40/MKBW2W4Rhis/DbILU74C1vSrLJxCq57o941Ym01SwNsOMqvEBFlcgUa6xLiPY/NS5R+E6ztJQ=="
    crossorigin="anonymous" referrerpolicy="no-referrer">
    <link rel="stylesheet" href="../../css/blogproject.css">
    <link rel="stylesheet" href="../../css/fonts.css">
    <title>Document</title>

</head>

<body>
    <div class="parent">
        <div class="header">
            <h1>Samuel Haile</h1>
            <hr><hr style="margin-bottom: 5px;">
            <div class="links">
                <div class="item1"><a href="../../index.html">Home</a></div>
                <div class="item2"><a href="../../blog.html">Blog</a></div>
                <div class="item3"><a href="../../index.html">Projects</a></div>
            </div>
            <hr style="margin-top: 5px;"><hr>
        </div>
        <div class="title">
            <h1>Parallax Occlusion Mapping with AI-Generated Depth Maps Using MIDAS</h1>
            <small >PUBLISHED ON <i>August 17, 2023 </i> by Samuel Haile </small>
            <hr style="margin-top: 10px; width: 137%;">
        </div>
        <div class="sidebar">
            <div class="contact">
                    <a href="https://www.linkedin.com/in/samuel-haile-77140021b/"><i
                            class="fab fa-linkedin"></i></a>
                    <a href="mailto:sdh5898@g.rit.edu"><i class="fa fa-solid fa-envelope"></i></a>
                    <a href="media/Haile_Samuel_Resume.pdf"><i class="fa fa-regular fa-file"></i></a>
                    <a href="https://github.com/Sam-Haile"><i class="fab fa-github"></i></a>
            </div>
            <h2>Latest Articles</h2>
            <hr style="margin-top: 10%;">
            <p><a href="../470project0/project0.html">Physical Comp and Alt Interfaces: Get to Know Your Tools</a></p>
            <small>September 3, 2023</small>
            <hr style="margin-top: 5%;">
            <p><a href="../470project1/project1.html">Physical Comp and Alt Interfaces: Introduction and Setup</a></p>
            <small>September 3, 2023</small>
            <hr style="margin-top: 5%;">
            <p><a href="../project1/project1.html">Parallax Occlusion Mapping with AI-Generated Depth Maps</a></p>
            <small>September 3, 2023</small>
            <hr style="margin-top: 5%;">
        </div>
        <div class="content">
            <img src="media/depthmapfrom2dfoxexample.jpg"> 
            <p>In the realm of computer graphics, achieving realistic textures and surfaces is paramount. Parallax Occlusion Mapping
                (POM) has long been a favorite technique to simulate 3D details on 2D surfaces. But what if we could enhance this with
                the power of AI? Enter MIDAS, a state-of-the-art tool for depth map prediction.
            </p>

            
            <div class="content-wrapper">
                <div class="text">
                    <h2>Understanding Parallax Occlusion Mapping (POM)</h2>
                        <p> POM is a technique that simulates the appearance of depth on a 2D texture. It works by altering the texture coordinates
                            based on the viewer's perspective and a height map, giving the illusion of 3D depth. This is especially useful for
                            surfaces with intricate details that would be computationally expensive to model in 3D. </p>
                    </div>
                    <div class="image">
                        <img src= "media/midas_samples.png" alt="image of midas_samples"> 
                    </div>
                </div>



            <h2>MIDAS: The Power of AI in Depth Map Prediction</h2>
            <p>MIDAS, which stands for Mi-Depth Inference System, is a deep learning model trained to predict depth maps from 2D
                images. Unlike traditional methods, MIDAS can generate depth maps with remarkable accuracy and detail. This is
                achieved by training the model on a vast dataset of images with corresponding depth maps, allowing it to generalize
                and predict depth for new, unseen images.
            </p>

            <h2>Combining POM with MIDAS</h2>
            <p>By integrating POM with AI-generated depth maps from MIDAS, we can achieve:</p>
            <ul>
                <li><strong>Enhanced Realism:</strong> The depth maps generated by MIDAS provide a higher level of detail, making the POM effect more pronounced and realistic.</li>
                <li><strong>Efficiency:</strong> Instead of manually creating height maps for POM, MIDAS can automatically generate them, saving time and effort.</li>
                <li><strong>Dynamic Depth Generation:</strong> For dynamic scenes or those with changing textures, MIDAS can generate depth maps on-the-fly, allowing for real-time POM effects.
                </li>
            </ul>

            <h2>Implementation Steps</h2>
            <ul>
                <li><strong>Preparation:</strong> Obtain the 2D texture for which you want to apply the POM effect.</li>
                <li><strong>Efficiency:</strong> Use MIDAS to generate a depth map for the texture.</li>
                <li><strong>Dynamic Depth Generation:</strong> Integrate the depth map with your rendering engine to apply the POM effect based on the AI-generated depth map.</li>
            </ul>

            <h2>Conclusion</h2>
            <p>The fusion of traditional graphics techniques like POM with cutting-edge AI tools like MIDAS opens up new horizons in
                the world of computer graphics. By automating and enhancing processes, we can achieve greater realism and efficiency
                in our digital creations.</p>

        </div>
    </div>
</body>

</html>